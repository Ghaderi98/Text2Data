{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1plv-5NWcHz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from openai import OpenAIApi\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Step 1: Dataset Generation using OpenAI API\n",
        "api_key = 'your_openai_api_key_here'  # Replace with your OpenAI API key\n",
        "openai = OpenAIApi(api_key)\n",
        "\n",
        "# Function to generate formal dates from informal dates using GPT-3\n",
        "def generate_formal_dates(informal_dates):\n",
        "    formal_dates = []\n",
        "    for informal_date in informal_dates:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",\n",
        "            prompt=f\"Convert the informal date '{informal_date}' into a formal date format like 'YYYY/MM/DD'.\",\n",
        "            max_tokens=50\n",
        "        )\n",
        "        formal_dates.append(response.choices[0].text.strip())\n",
        "    return formal_dates\n",
        "\n",
        "# Informal dates list\n",
        "informal_dates = [\n",
        "    \"1 1403 Mehr\",\n",
        "    \"First Mehr 1403\",\n",
        "    \"Mehr 1403\",\n",
        "    \"Mehr month 1403\",\n",
        "    \"5 Aban 1403\",\n",
        "    \"25 Azar 1403\",\n",
        "    \"30 Tir 1403\",\n",
        "    \"Thursday 5 Aban 1403\",\n",
        "    \"1 Farvardin 1403\",\n",
        "    \"Last day of Tir 1403\",\n",
        "    \"14 Dey 1403\",\n",
        "    \"8 Bahman 1403\",\n",
        "    \"1403/07/01\",\n",
        "    \"1403-07-01\",\n",
        "    \"1403/08/05\",\n",
        "    \"1403/09/25\"\n",
        "]\n",
        "\n",
        "# Generate formal dates using OpenAI API\n",
        "formal_dates = generate_formal_dates(informal_dates)\n",
        "\n",
        "# Create DataFrame\n",
        "data = {\n",
        "    \"informal_date\": informal_dates,\n",
        "    \"formal_date\": formal_dates\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save and Display Dataset\n",
        "df.to_csv('date_conversion_dataset.csv', index=False)\n",
        "print(df)\n",
        "\n",
        "# Step 2: Data Preparation\n",
        "# Load the dataset\n",
        "df = pd.read_csv('date_conversion_dataset.csv')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Model Training (unchanged)\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Tokenize the data\n",
        "train_encodings = tokenizer(train_data['informal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "train_labels = tokenizer(train_data['formal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "test_encodings = tokenizer(test_data['informal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "test_labels = tokenizer(test_data['formal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "# Model Training\n",
        "# (Your existing model training code here)\n",
        "\n",
        "# Step 4: Model Evaluation (unchanged)\n",
        "# (Your existing model evaluation code here)\n"
      ]
    }
  ]
}