{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai transformers torch pandas scikit-learn\n"
      ],
      "metadata": {
        "id": "VxGX0ricXQi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# **Step 1: Dataset Generation with OpenAI API**\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = 'your_openai_api_key_here'\n",
        "\n",
        "# Function to generate informal dates using OpenAI's API\n",
        "def generate_informal_dates(prompts):\n",
        "    informal_dates = []\n",
        "    for prompt in prompts:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",  # Use the GPT-3.5 model for generating text\n",
        "            prompt=prompt,\n",
        "            max_tokens=30,\n",
        "            n=1,\n",
        "            stop=None,\n",
        "            temperature=0.5  # Adjust temperature for more or less randomness\n",
        "        )\n",
        "        informal_dates.append(response['choices'][0]['text'].strip())\n",
        "    return informal_dates\n",
        "\n",
        "# Predefined prompts for generating informal date variations\n",
        "prompts = [\n",
        "    \"Generate informal date for: 1403/07/01\",\n",
        "    \"Generate informal date for: 1403/07/01\",\n",
        "    \"Generate informal date for: 1403/08/05\",\n",
        "    \"Generate informal date for: 1403/09/25\",\n",
        "    \"Generate informal date for: 1403/04/30\",\n",
        "    \"Generate informal date for: 1403/01/01\",\n",
        "    \"Generate informal date for: 1403/10/14\",\n",
        "    \"Generate informal date for: 1403/11/08\"\n",
        "]\n",
        "\n",
        "# Generate informal dates from OpenAI\n",
        "informal_dates = generate_informal_dates(prompts)\n",
        "\n",
        "# Corresponding formal formats (known correct dates)\n",
        "formal_dates = [\n",
        "    \"1403/07/01\",  # Formal date\n",
        "    \"1403/07/01\",  # Formal date\n",
        "    \"1403/08/05\",  # Formal date with day\n",
        "    \"1403/09/25\",  # Formal date with day\n",
        "    \"1403/04/30\",  # Formal date with day\n",
        "    \"1403/01/01\",  # Formal date\n",
        "    \"1403/10/14\",  # Formal date with day\n",
        "    \"1403/11/08\"   # Formal date with day\n",
        "]\n",
        "\n",
        "# Create a DataFrame to store the generated informal dates and their formal counterparts\n",
        "data = {\n",
        "    \"informal_date\": informal_dates,\n",
        "    \"formal_date\": formal_dates\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "df.to_csv('date_conversion_dataset.csv', index=False)\n",
        "print(df)\n",
        "\n",
        "# **Step 2: Data Preparation**\n",
        "# Load the dataset\n",
        "df = pd.read_csv('date_conversion_dataset.csv')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the T5 tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Tokenize the data\n",
        "train_encodings = tokenizer(train_data['informal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "train_labels = tokenizer(train_data['formal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "test_encodings = tokenizer(test_data['informal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "test_labels = tokenizer(test_data['formal_date'].tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "# **Step 3: Model Training**\n",
        "# Create data loaders\n",
        "train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_labels['input_ids'])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Training settings\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "model.train()\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(5):  # Increase the number of epochs for better learning\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, labels = batch\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# **Step 4: Model Evaluation**\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "test_encodings = test_encodings['input_ids']\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(test_encodings)\n",
        "\n",
        "# Decode tokens to text\n",
        "decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "# Function to ensure correct year, month, and format in predictions\n",
        "def correct_date_format(predicted, informal):\n",
        "    # Define month keywords and their corresponding numbers\n",
        "    month_keywords = {\n",
        "        \"Farvardin\": \"01\",\n",
        "        \"Ordibehesht\": \"02\",\n",
        "        \"Khordad\": \"03\",\n",
        "        \"Tir\": \"04\",\n",
        "        \"Mordad\": \"05\",\n",
        "        \"Shahrivar\": \"06\",\n",
        "        \"Mehr\": \"07\",\n",
        "        \"Aban\": \"08\",\n",
        "        \"Azar\": \"09\",\n",
        "        \"Dey\": \"10\",\n",
        "        \"Bahman\": \"11\",\n",
        "        \"Esfand\": \"12\"\n",
        "    }\n",
        "    # Extract year from the informal date\n",
        "    year = None\n",
        "    for part in informal.split():\n",
        "        if part.isdigit() and len(part) == 4:  # Check if it's a year\n",
        "            year = part\n",
        "    # Find the month from informal input\n",
        "    month_number = None\n",
        "    for month_name, month_num in month_keywords.items():\n",
        "        if month_name in informal:\n",
        "            month_number = month_num\n",
        "            break\n",
        "    # Extract day from the predicted output\n",
        "    parts = predicted.split('/')\n",
        "    if len(parts) == 3:\n",
        "        day = parts[2]  # Use the day part from predicted\n",
        "    else:\n",
        "        day = '01'  # Default day if not found\n",
        "    # If year is found, construct the final date\n",
        "    if year and month_number:\n",
        "        return f\"{year}/{month_number}/{day.zfill(2)}\"\n",
        "    return predicted  # Return the original if no month or year is found\n",
        "\n",
        "# Display results\n",
        "for informal, formal, decoded in zip(test_data['informal_date'], test_data['formal_date'], decoded_outputs):\n",
        "    corrected_decoded = correct_date_format(decoded, informal)\n",
        "    print(f'Informal: {informal}, Expected: {formal}, Predicted: {corrected_decoded}')\n"
      ],
      "metadata": {
        "id": "JnAG2Q85Xbai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}